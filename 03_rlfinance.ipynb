{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "475819a4-e148-4616-b1cb-44b659aeb08a",
      "metadata": {
        "id": "475819a4-e148-4616-b1cb-44b659aeb08a"
      },
      "source": [
        "<img src=\"http://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e",
      "metadata": {
        "id": "280cc0c6-2c18-46cd-8af7-3f19b64a6d7e"
      },
      "source": [
        "# Reinforcement Learning for Finance\n",
        "\n",
        "**Chapter 03 &mdash; Financial Q-Learning**\n",
        "\n",
        "&copy; Dr. Yves J. Hilpisch\n",
        "\n",
        "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6be6f8b-e00e-402c-9df1-1d3f16e76c7e",
      "metadata": {
        "id": "d6be6f8b-e00e-402c-9df1-1d3f16e76c7e"
      },
      "source": [
        "## Finance Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd68580f",
      "metadata": {
        "id": "dd68580f"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tpq-classes/rl_4_finance.git\n",
        "import sys\n",
        "sys.path.append('rl_4_finance')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2f885c-c149-4f96-a5b2-8a71663fbcb6",
      "metadata": {
        "id": "7a2f885c-c149-4f96-a5b2-8a71663fbcb6"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb33cd0c-4fb1-4456-911f-0d92597db8c0",
      "metadata": {
        "id": "cb33cd0c-4fb1-4456-911f-0d92597db8c0"
      },
      "outputs": [],
      "source": [
        "class ActionSpace:\n",
        "    def sample(self):\n",
        "        return random.randint(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d49bdd-e24b-4d87-a4dc-5639cc172f8e",
      "metadata": {
        "id": "30d49bdd-e24b-4d87-a4dc-5639cc172f8e"
      },
      "outputs": [],
      "source": [
        "action_space = ActionSpace()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416ce315-16d7-4c47-845a-f21a099b8ba3",
      "metadata": {
        "id": "416ce315-16d7-4c47-845a-f21a099b8ba3"
      },
      "outputs": [],
      "source": [
        "[action_space.sample() for _ in range(10)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4df457f-9014-4e6a-878a-23645c77037d",
      "metadata": {
        "id": "f4df457f-9014-4e6a-878a-23645c77037d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import plt\n",
        "plt.style.use('seaborn-v0_8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573288f6-434b-4cb0-bc05-3bbc7bdad73b",
      "metadata": {
        "id": "573288f6-434b-4cb0-bc05-3bbc7bdad73b"
      },
      "outputs": [],
      "source": [
        "url = 'https://certificate.tpq.io/rl4finance.csv'\n",
        "data = pd.read_csv(url, index_col=0, parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc75790-0f2d-4f11-9222-b93ceb4856dd",
      "metadata": {
        "id": "4fc75790-0f2d-4f11-9222-b93ceb4856dd"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2833dbbb-b549-4f5e-ab88-628cecf9ff9a",
      "metadata": {
        "id": "2833dbbb-b549-4f5e-ab88-628cecf9ff9a"
      },
      "outputs": [],
      "source": [
        "# data['EUR='].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "952353e1-8f39-48ac-ac6d-5a21b9a44315",
      "metadata": {
        "id": "952353e1-8f39-48ac-ac6d-5a21b9a44315"
      },
      "outputs": [],
      "source": [
        "class Finance:\n",
        "    # url = 'https://certificate.tpq.io/findata.csv'  # <1>\n",
        "    url = 'https://certificate.tpq.io/rl4finance.csv'  # <1>\n",
        "    def __init__(self, symbol, feature, min_accuracy=0.485, n_features=4):\n",
        "        self.symbol = symbol  # <2>\n",
        "        self.feature = feature  # <3>\n",
        "        self.n_features = n_features  # <4>\n",
        "        self.action_space = ActionSpace()  # <5>\n",
        "        self.min_accuracy = min_accuracy  # <6>\n",
        "        self._get_data()  # <7>\n",
        "        self._prepare_data()  # <8>\n",
        "    def _get_data(self):\n",
        "        self.raw = pd.read_csv(self.url,\n",
        "                index_col=0, parse_dates=True)  # <7>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e1ed75-1e55-42f4-86a3-db54c60acf1f",
      "metadata": {
        "id": "69e1ed75-1e55-42f4-86a3-db54c60acf1f"
      },
      "outputs": [],
      "source": [
        "class Finance(Finance):\n",
        "    def _prepare_data(self):\n",
        "        self.data = pd.DataFrame(self.raw[self.symbol]).dropna()  # <1>\n",
        "        self.data['r'] = np.log(self.data / self.data.shift(1))  # <2>\n",
        "        self.data['d'] = np.where(self.data['r'] > 0, 1, 0)  # <3>\n",
        "        self.data.dropna(inplace=True)  # <4>\n",
        "        self.data_ = (self.data - self.data.mean()) / self.data.std()  #  <5>\n",
        "    def reset(self):\n",
        "        self.bar = self.n_features  # <5>\n",
        "        self.treward = 0  # <6>\n",
        "        state = self.data_[self.feature].iloc[\n",
        "            self.bar - self.n_features:self.bar].values  # <7>\n",
        "        return state, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b0ccc6-d8ec-4156-bf7a-30ba263fdde9",
      "metadata": {
        "id": "a2b0ccc6-d8ec-4156-bf7a-30ba263fdde9"
      },
      "outputs": [],
      "source": [
        "class Finance(Finance):\n",
        "    def step(self, action):\n",
        "        if action == self.data['d'].iloc[self.bar]:  # <1>\n",
        "            correct = True\n",
        "        else:\n",
        "            correct = False\n",
        "        reward = 1 if correct else 0  # <2>\n",
        "        self.treward += reward  # <3>\n",
        "        self.bar += 1  # <4>\n",
        "        self.accuracy = self.treward / (self.bar - self.n_features)  # <5>\n",
        "        if self.bar >= len(self.data):  # <6>\n",
        "            done = True\n",
        "        elif reward == 1:  # <7>\n",
        "            done = False\n",
        "        elif (self.accuracy < self.min_accuracy) and (self.bar > 15):  # <8>\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "        next_state = self.data_[self.feature].iloc[\n",
        "            self.bar - self.n_features:self.bar].values  # <9>\n",
        "        return next_state, reward, done, False, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373a0a8c-3b85-4933-8de5-1103d4cc1a6b",
      "metadata": {
        "id": "373a0a8c-3b85-4933-8de5-1103d4cc1a6b"
      },
      "outputs": [],
      "source": [
        "fin = Finance(symbol='EUR=', feature='EUR=', n_features=4)  # <1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c4248b-2168-42d2-b766-27270681b5dd",
      "metadata": {
        "id": "d4c4248b-2168-42d2-b766-27270681b5dd"
      },
      "outputs": [],
      "source": [
        "list(fin.raw.columns)  # <2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c2042dd-3d9a-4976-bb6d-d58daeeaf650",
      "metadata": {
        "id": "0c2042dd-3d9a-4976-bb6d-d58daeeaf650"
      },
      "outputs": [],
      "source": [
        "fin.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bc5dd1-76cd-47ff-abde-9fac65bd6234",
      "metadata": {
        "id": "41bc5dd1-76cd-47ff-abde-9fac65bd6234"
      },
      "outputs": [],
      "source": [
        "# fin.data_['EUR='].mean(), fin.data_['EUR='].std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5427c044-9504-458a-b1fb-13459b08d695",
      "metadata": {
        "id": "5427c044-9504-458a-b1fb-13459b08d695"
      },
      "outputs": [],
      "source": [
        "# fin.data_['EUR='].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e04a87-7f63-4532-8609-2ad598d67067",
      "metadata": {
        "id": "d0e04a87-7f63-4532-8609-2ad598d67067"
      },
      "outputs": [],
      "source": [
        "fin.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6a11b6-87da-4226-baad-0fa9f4942c44",
      "metadata": {
        "id": "2c6a11b6-87da-4226-baad-0fa9f4942c44"
      },
      "outputs": [],
      "source": [
        "fin.step(fin.action_space.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a3b905-2eea-406f-9bee-bb61d6f5e463",
      "metadata": {
        "id": "c0a3b905-2eea-406f-9bee-bb61d6f5e463"
      },
      "outputs": [],
      "source": [
        "fin = Finance('EUR=', 'r')  # <3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c490647f-9757-46bf-911d-c53477d9b3d0",
      "metadata": {
        "id": "c490647f-9757-46bf-911d-c53477d9b3d0"
      },
      "outputs": [],
      "source": [
        "fin.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0bab87-6d45-4e17-a52c-3d19273bd804",
      "metadata": {
        "id": "1c0bab87-6d45-4e17-a52c-3d19273bd804"
      },
      "outputs": [],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self):\n",
        "        self.env = Finance('EUR=', 'r')\n",
        "    def play(self, episodes=1):\n",
        "        self.trewards = list()\n",
        "        for e in range(episodes):\n",
        "            self.env.reset()\n",
        "            for step in range(1, 100):\n",
        "                a = self.env.action_space.sample()\n",
        "                state, reward, done, trunc, info = self.env.step(a)\n",
        "                if done:\n",
        "                    self.trewards.append(step)\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417b3f00-199f-4db7-b500-b7b7f99ce15b",
      "metadata": {
        "id": "417b3f00-199f-4db7-b500-b7b7f99ce15b"
      },
      "outputs": [],
      "source": [
        "ra = RandomAgent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99850e42-8c2b-46a6-9a92-59a0e5940061",
      "metadata": {
        "id": "99850e42-8c2b-46a6-9a92-59a0e5940061"
      },
      "outputs": [],
      "source": [
        "ra.play(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6351f5-e532-4703-ae3b-0f7ec2483f48",
      "metadata": {
        "id": "1a6351f5-e532-4703-ae3b-0f7ec2483f48"
      },
      "outputs": [],
      "source": [
        "ra.trewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9590104e-899f-4a4a-81a3-0b952a8f1818",
      "metadata": {
        "id": "9590104e-899f-4a4a-81a3-0b952a8f1818"
      },
      "outputs": [],
      "source": [
        "round(sum(ra.trewards) / len(ra.trewards), 2)  # <1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2252d5e0-0c3f-4900-a96f-1fe6348ccd18",
      "metadata": {
        "id": "2252d5e0-0c3f-4900-a96f-1fe6348ccd18"
      },
      "outputs": [],
      "source": [
        "len(fin.data)  # <2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04e9dcb-5a0c-463b-9714-012a9b8e4093",
      "metadata": {
        "id": "a04e9dcb-5a0c-463b-9714-012a9b8e4093"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e651e5-4eb4-4001-b8a3-d629721b6eed",
      "metadata": {
        "id": "06e651e5-4eb4-4001-b8a3-d629721b6eed"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from collections import deque\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5656a5-7378-494b-a43f-5ba736105485",
      "metadata": {
        "id": "9c5656a5-7378-494b-a43f-5ba736105485"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde4e8cb",
      "metadata": {
        "auto_refactor_role": "generated",
        "id": "cde4e8cb"
      },
      "outputs": [],
      "source": [
        "class DQLAgent:\n",
        "    def __init__(self, symbol, feature, min_accuracy, n_features=4):\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_decay = 0.9975\n",
        "        self.epsilon_min = 0.1\n",
        "        self.memory = list()\n",
        "        self.batch_size = 32\n",
        "        self.gamma = 0.5\n",
        "        self.trewards = deque(maxlen=2000)\n",
        "        self.max_treward = 0\n",
        "        self.n_features = n_features\n",
        "        self._create_model()\n",
        "        self.env = Finance(symbol, feature,\n",
        "                    min_accuracy, n_features)  # <1>\n",
        "    def _create_model(self):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Dense(24, activation='relu',\n",
        "                             input_dim=self.n_features))\n",
        "        self.model.add(Dense(24, activation='relu'))\n",
        "        self.model.add(Dense(2, activation='linear'))\n",
        "        self.model.compile(loss='mse', optimizer=opt)\n",
        "\n",
        "    def act(self, state):\n",
        "        if random.random() < self.epsilon:\n",
        "            return self.env.action_space.sample()\n",
        "        q = self.model(tf.convert_to_tensor(state, dtype=tf.float32), training=False)\n",
        "        return int(tf.argmax(q[0]).numpy())\n",
        "\n",
        "    def replay(self):\n",
        "        batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        states      = np.vstack([b[0] for b in batch]).astype(np.float32)\n",
        "        actions     = np.array([b[1] for b in batch], dtype=np.int32)\n",
        "        next_states = np.vstack([b[2] for b in batch]).astype(np.float32)\n",
        "        rewards     = np.array([b[3] for b in batch], dtype=np.float32)\n",
        "        dones       = np.array([b[4] for b in batch], dtype=np.bool_)\n",
        "\n",
        "        # Q(s, :)\n",
        "        q_states = self.model(states, training=False).numpy()          # (B, A)\n",
        "\n",
        "        # max_a' Q(s', a')\n",
        "        q_next = self.model(next_states, training=False).numpy()       # (B, A)\n",
        "        max_q_next = np.max(q_next, axis=1)                            # (B,)\n",
        "\n",
        "        targets = q_states.copy()\n",
        "        targets[np.arange(self.batch_size), actions] = rewards + self.gamma * max_q_next * (~dones)\n",
        "\n",
        "         # One update only (FAST)\n",
        "        self.model.train_on_batch(states, targets)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def learn(self, episodes):\n",
        "        for e in range(1, episodes + 1):\n",
        "            state, _ = self.env.reset()\n",
        "            state = np.reshape(state, [1, self.n_features])\n",
        "            for f in range(1, 5000):\n",
        "                action = self.act(state)\n",
        "                next_state, reward, done, trunc, _ = self.env.step(action)\n",
        "                next_state = np.reshape(next_state, [1, self.n_features])\n",
        "                self.memory.append(\n",
        "                    [state, action, next_state, reward, done])\n",
        "                state = next_state\n",
        "                if done:\n",
        "                    self.trewards.append(f)\n",
        "                    self.max_treward = max(self.max_treward, f)\n",
        "                    templ = f'episode={e:4d} | treward={f:4d}'\n",
        "                    templ += f' | max={self.max_treward:4d}'\n",
        "                    print(templ, end='\\r')\n",
        "                    break\n",
        "            if len(self.memory) > self.batch_size:\n",
        "                self.replay()\n",
        "        print()\n",
        "    def test(self, episodes):\n",
        "        ma = self.env.min_accuracy  # <2>\n",
        "        self.env.min_accuracy = 0.5  # <3>\n",
        "        for e in range(1, episodes + 1):\n",
        "            state, _ = self.env.reset()\n",
        "            state = np.reshape(state, [1, self.n_features])\n",
        "            for f in range(1, 5001):\n",
        "                action = np.argmax(self.model(tf.convert_to_tensor(state, dtype=tf.float32), training=False).numpy()[0])\n",
        "                state, reward, done, trunc, _ = self.env.step(action)\n",
        "                state = np.reshape(state, [1, self.n_features])\n",
        "                if done:\n",
        "                    print(f'total reward={f} | accuracy={self.env.accuracy:.3f}')\n",
        "                    break\n",
        "        self.env.min_accuracy = ma  # <2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268f6f90-082d-4827-bdef-8bffa57016c7",
      "metadata": {
        "id": "268f6f90-082d-4827-bdef-8bffa57016c7"
      },
      "outputs": [],
      "source": [
        "agent = DQLAgent('EUR=', 'r', 0.495, 4)  # normalized returns as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1f656f-5217-4a09-a4d2-8391d5c30a7f",
      "metadata": {
        "id": "cf1f656f-5217-4a09-a4d2-8391d5c30a7f"
      },
      "outputs": [],
      "source": [
        "# agent = DQLAgent('EUR=', 'EUR=', 0.45, 4)  # normalized price data as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6e4b43-1703-40e9-b405-3fcef172811c",
      "metadata": {
        "id": "bc6e4b43-1703-40e9-b405-3fcef172811c"
      },
      "outputs": [],
      "source": [
        "# agent = DQLAgent('AAPL.O', 'r', 0.495, 4)  # normalized returns as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68788c7a-1e96-4a8d-bd70-147c1f75a523",
      "metadata": {
        "id": "68788c7a-1e96-4a8d-bd70-147c1f75a523"
      },
      "outputs": [],
      "source": [
        "# agent = DQLAgent('AAPL.O', 'AAPL.O', 0.495, 4)  # normalized price data as features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718a98db-efef-44d2-833b-bf0e926cfe73",
      "metadata": {
        "id": "718a98db-efef-44d2-833b-bf0e926cfe73"
      },
      "outputs": [],
      "source": [
        "# agent = DQLAgent('AAPL.O', 'r', 0.495, 8)  # normalized returns data as features (8 instead of 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae2336af-de7e-4b3a-8ecd-292a06a0beb4",
      "metadata": {
        "id": "ae2336af-de7e-4b3a-8ecd-292a06a0beb4"
      },
      "outputs": [],
      "source": [
        "%time agent.learn(333)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1023a5-07ef-4ac3-86c4-307a356cd2ba",
      "metadata": {
        "id": "6a1023a5-07ef-4ac3-86c4-307a356cd2ba"
      },
      "outputs": [],
      "source": [
        "agent.test(5)  # <1>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55",
      "metadata": {
        "id": "20e3eaa7-ac35-44e5-bffc-93662c2d2c55"
      },
      "source": [
        "<img src=\"http://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" align=\"right\" border=\"0\"><br>\n",
        "\n",
        "<a href=\"http://tpq.io\" target=\"_blank\">http://tpq.io</a> | <a href=\"http://twitter.com/dyjh\" target=\"_blank\">@dyjh</a> | <a href=\"mailto:team@tpq.io\">team@tpq.io</a>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
